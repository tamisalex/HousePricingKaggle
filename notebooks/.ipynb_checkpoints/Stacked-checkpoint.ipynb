{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk \n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, KFold\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from scipy.stats import skew\n",
    "import keras\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertNA(value):\n",
    "    try:\n",
    "        if np.isnan(value):\n",
    "            return \"None\"\n",
    "        else:\n",
    "            return value\n",
    "    except:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeSubmission(predictions,testDF):\n",
    "    submission = pd.DataFrame()\n",
    "    submission[\"Id\"] = testDF[\"Id\"]\n",
    "    submission[\"SalePrice\"] = predictions\n",
    "    submission.to_csv(\"../assets/submission_stacked_\"+ datetime.now().strftime(\"%Y%m%d-%H%M%S\") +\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rmsle(y_predict,y_actual):\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y_predict) - np.log1p(y_actual), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read, Clean, Create Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train  = pd.read_csv(\"../assets/train.csv\")\n",
    "test = pd.read_csv(\"../assets/test.csv\")\n",
    "\n",
    "all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n",
    "                      test.loc[:,'MSSubClass':'SaleCondition']))\n",
    "\n",
    "categories = [u\"Alley\",\"Fence\",\"PoolQC\",\"GarageCond\",\"GarageQual\",\"GarageFinish\",\"MiscFeature\",\"GarageType\",\"FireplaceQu\",\"BsmtFinType2\",\"BsmtFinType1\",\"BsmtCond\",\"BsmtQual\"]\n",
    "for column in categories:\n",
    "    all_data[column] = all_data[column].apply(convertNA)\n",
    "\n",
    "all_data.fillna(all_data.mean(),inplace=True)\n",
    "\n",
    "all_data = pd.get_dummies(all_data)\n",
    "\n",
    "X = all_data.iloc[:1460,:]\n",
    "X_test = all_data.iloc[1460:,:]\n",
    "y = train[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Functions for Each Model Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runRFModel(X,y,X_test):\n",
    "    cv = KFold(len(y),shuffle=False)\n",
    "    rf = RandomForestRegressor(random_state=5)\n",
    "    rfScore = cross_val_score(rf,X,y,cv=cv, n_jobs=-1)\n",
    "    model = rf.fit(X,y)\n",
    "\n",
    "    predictions =  model.predict(X)\n",
    "    print \"Score: \", metrics.r2_score(y,predictions)\n",
    "    print \"RMSLE: \", rmsle(y,predictions)\n",
    "\n",
    "    return predictions,model.predict(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, X, X_test, y, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X.values, label=y.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='rmse', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X, y,eval_metric='rmse')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X)\n",
    "    dtest_predictions = alg.predict(X_test)\n",
    "    \n",
    "    #dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    #Print model report:\n",
    "    #print \"\\nModel Report\"\n",
    "    #print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['SalePrice'].values.astype(float), dtrain_predictions.astype(float))\n",
    "    #print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['SalePrice'], dtrain_predprob)\n",
    "    #print \"Score: \", metrics.r2_score(y,dtrain_predictions)\n",
    "    #print \"RMSLE: \", rmsle(y,dtrain_predictions)\n",
    "    #feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    #feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    #plt.ylabel('Feature Importance Score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runXGB(X,y,X_test):\n",
    "    xgb1 = xgb.XGBRegressor(\n",
    "     learning_rate =0.01,\n",
    "     n_estimators=1000,\n",
    "     max_depth=6,\n",
    "     min_child_weight=3,\n",
    "     gamma=0,\n",
    "     subsample=0.65,\n",
    "     colsample_bytree=0.65,\n",
    "     objective= 'reg:linear',\n",
    "     nthread=4,\n",
    "     scale_pos_weight=1,\n",
    "     reg_alpha= 1e-05,\n",
    "     seed=27)\n",
    "    model = modelfit(xgb1, X, X_test, y)\n",
    "\n",
    "    predictions =  xgb1.predict(X)\n",
    "    print \"Score: \", metrics.r2_score(y,predictions)\n",
    "    print \"RMSLE: \", rmsle(y,predictions)\n",
    "\n",
    "    return predictions, xgb1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runLinReg(X,y,X_test):\n",
    "    #log transform the target:\n",
    "    #y = np.log1p(y)\n",
    "\n",
    "    #log transform skewed numeric features:\n",
    "    numeric_feats = X.dtypes[X.dtypes != \"object\"].index\n",
    "\n",
    "    skewed_feats = X[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "    skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "    skewed_feats = skewed_feats.index\n",
    "    \n",
    "    skewed_feats_test = X_test[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "    skewed_feats_test = skewed_feats_test[skewed_feats_test > 0.75]\n",
    "    skewed_feats_test = skewed_feats_test.index\n",
    "\n",
    "    X[skewed_feats] = np.log1p(X[skewed_feats])\n",
    "    X_test[skewed_feats_test] = np.log1p(X_test[skewed_feats_test])\n",
    "    \n",
    "    model_lasso = LassoCV(cv=1000,alphas = [100,10,1, 0.1, 0.001, 0.0005], max_iter = 50000, verbose = 1, n_jobs=-1).fit(X, y)\n",
    "    \n",
    "    predictions =  model_lasso.predict(X)\n",
    "    print \"Score: \", metrics.r2_score(y,predictions)\n",
    "    print \"RMSLE: \", rmsle(y,predictions)\n",
    "\n",
    "    return predictions, model_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the models and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_predictions,rf_predictions_test = runRFModel(X,y,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_predictions,xgb_predictions_test = runXGB(X,y,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr_predictions,lr_predictions_test = runLinReg(X,y,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "level1 = pd.DataFrame()\n",
    "level1[\"rf\"] = rf_predictions\n",
    "level1[\"xgb\"] = xgb_predictions\n",
    "level1[\"lr\"] = lr_predictions\n",
    "level1[\"y\"] = y\n",
    "level1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level1_test = pd.DataFrame()\n",
    "level1_test[\"rf\"] = rf_predictions_test\n",
    "level1_test[\"xgb\"] = xgb_predictions_test\n",
    "level1_test[\"lr\"] = lr_predictions_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'level1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-df0d5a04cb25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlevel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../assets/Level1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlevel1_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../assets/Level1_test.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'level1' is not defined"
     ]
    }
   ],
   "source": [
    "level1.to_csv(\"../assets/Level1.csv\",index=False)\n",
    "level1_test.to_csv(\"../assets/Level1_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>lr</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208400.0</td>\n",
       "      <td>204554.875000</td>\n",
       "      <td>211728.158201</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173000.0</td>\n",
       "      <td>176239.093750</td>\n",
       "      <td>197396.677529</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217000.0</td>\n",
       "      <td>214539.015625</td>\n",
       "      <td>215014.330002</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142400.0</td>\n",
       "      <td>153358.062500</td>\n",
       "      <td>185803.006791</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>265309.0</td>\n",
       "      <td>272659.000000</td>\n",
       "      <td>310234.037357</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rf            xgb             lr       y\n",
       "0  208400.0  204554.875000  211728.158201  208500\n",
       "1  173000.0  176239.093750  197396.677529  181500\n",
       "2  217000.0  214539.015625  215014.330002  223500\n",
       "3  142400.0  153358.062500  185803.006791  140000\n",
       "4  265309.0  272659.000000  310234.037357  250000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural = pd.read_csv(\"../assets/Level1.csv\")\n",
    "neural.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126480.0</td>\n",
       "      <td>127040.242188</td>\n",
       "      <td>50689.422559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151420.0</td>\n",
       "      <td>156986.437500</td>\n",
       "      <td>87161.067545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183290.0</td>\n",
       "      <td>183298.046875</td>\n",
       "      <td>112640.158636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184283.2</td>\n",
       "      <td>190673.109375</td>\n",
       "      <td>122685.092072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197240.0</td>\n",
       "      <td>189672.546875</td>\n",
       "      <td>175280.182603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rf            xgb             lr\n",
       "0  126480.0  127040.242188   50689.422559\n",
       "1  151420.0  156986.437500   87161.067545\n",
       "2  183290.0  183298.046875  112640.158636\n",
       "3  184283.2  190673.109375  122685.092072\n",
       "4  197240.0  189672.546875  175280.182603"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_test = pd.read_csv(\"../assets/Level1_test.csv\")\n",
    "neural_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_X = neural.values[:,0:3]\n",
    "net_Y = neural.values[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# define base mode\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(3, input_dim=3, init='normal', activation='relu'))\n",
    "    #model.add(Dense(2, input_dim=2, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='msle', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=50, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n=len(net_X), n_folds=10, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "973/973 [==============================] - 0s - loss: 33.8523     \n",
      "Epoch 2/50\n",
      "973/973 [==============================] - 0s - loss: 18.1661     \n",
      "Epoch 3/50\n",
      "973/973 [==============================] - 0s - loss: 13.2210     \n",
      "Epoch 4/50\n",
      "973/973 [==============================] - 0s - loss: 10.3690     \n",
      "Epoch 5/50\n",
      "973/973 [==============================] - 0s - loss: 8.4478     \n",
      "Epoch 6/50\n",
      "973/973 [==============================] - 0s - loss: 7.0428     \n",
      "Epoch 7/50\n",
      "973/973 [==============================] - 0s - loss: 5.9609     \n",
      "Epoch 8/50\n",
      "973/973 [==============================] - 0s - loss: 5.0981     \n",
      "Epoch 9/50\n",
      "973/973 [==============================] - 0s - loss: 4.3923     \n",
      "Epoch 10/50\n",
      "973/973 [==============================] - 0s - loss: 3.8038     \n",
      "Epoch 11/50\n",
      "973/973 [==============================] - 0s - loss: 3.3058     \n",
      "Epoch 12/50\n",
      "973/973 [==============================] - 0s - loss: 2.8796     \n",
      "Epoch 13/50\n",
      "973/973 [==============================] - 0s - loss: 2.5115     \n",
      "Epoch 14/50\n",
      "973/973 [==============================] - 0s - loss: 2.1914     \n",
      "Epoch 15/50\n",
      "973/973 [==============================] - 0s - loss: 1.9115     \n",
      "Epoch 16/50\n",
      "973/973 [==============================] - 0s - loss: 1.6656     \n",
      "Epoch 17/50\n",
      "973/973 [==============================] - 0s - loss: 1.4491     \n",
      "Epoch 18/50\n",
      "973/973 [==============================] - 0s - loss: 1.2581     \n",
      "Epoch 19/50\n",
      "973/973 [==============================] - 0s - loss: 1.0892     \n",
      "Epoch 20/50\n",
      "973/973 [==============================] - 0s - loss: 0.9399     \n",
      "Epoch 21/50\n",
      "973/973 [==============================] - 0s - loss: 0.8081     \n",
      "Epoch 22/50\n",
      "973/973 [==============================] - 0s - loss: 0.6917     \n",
      "Epoch 23/50\n",
      "973/973 [==============================] - 0s - loss: 0.5892     \n",
      "Epoch 24/50\n",
      "973/973 [==============================] - 0s - loss: 0.4991     \n",
      "Epoch 25/50\n",
      "973/973 [==============================] - 0s - loss: 0.4203     \n",
      "Epoch 26/50\n",
      "973/973 [==============================] - 0s - loss: 0.3515     \n",
      "Epoch 27/50\n",
      "973/973 [==============================] - 0s - loss: 0.2919     \n",
      "Epoch 28/50\n",
      "973/973 [==============================] - 0s - loss: 0.2405     \n",
      "Epoch 29/50\n",
      "973/973 [==============================] - 0s - loss: 0.1964     \n",
      "Epoch 30/50\n",
      "973/973 [==============================] - 0s - loss: 0.1590     \n",
      "Epoch 31/50\n",
      "973/973 [==============================] - 0s - loss: 0.1274     \n",
      "Epoch 32/50\n",
      "973/973 [==============================] - 0s - loss: 0.1011     \n",
      "Epoch 33/50\n",
      "973/973 [==============================] - 0s - loss: 0.0794     \n",
      "Epoch 34/50\n",
      "973/973 [==============================] - 0s - loss: 0.0617     \n",
      "Epoch 35/50\n",
      "973/973 [==============================] - 0s - loss: 0.0475     \n",
      "Epoch 36/50\n",
      "973/973 [==============================] - 0s - loss: 0.0363     \n",
      "Epoch 37/50\n",
      "973/973 [==============================] - 0s - loss: 0.0277     \n",
      "Epoch 38/50\n",
      "973/973 [==============================] - 0s - loss: 0.0211     \n",
      "Epoch 39/50\n",
      "973/973 [==============================] - 0s - loss: 0.0162     \n",
      "Epoch 40/50\n",
      "973/973 [==============================] - 0s - loss: 0.0127     \n",
      "Epoch 41/50\n",
      "973/973 [==============================] - 0s - loss: 0.0102     \n",
      "Epoch 42/50\n",
      "973/973 [==============================] - 0s - loss: 0.0086     \n",
      "Epoch 43/50\n",
      "973/973 [==============================] - 0s - loss: 0.0075     \n",
      "Epoch 44/50\n",
      "973/973 [==============================] - 0s - loss: 0.0068     \n",
      "Epoch 45/50\n",
      "973/973 [==============================] - 0s - loss: 0.0064     \n",
      "Epoch 46/50\n",
      "973/973 [==============================] - 0s - loss: 0.0062     \n",
      "Epoch 47/50\n",
      "973/973 [==============================] - 0s - loss: 0.0061     \n",
      "Epoch 48/50\n",
      "973/973 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 49/50\n",
      "973/973 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 50/50\n",
      "973/973 [==============================] - 0s - loss: 0.0060     \n",
      "480/487 [============================>.] - ETA: 0sEpoch 1/50\n",
      "973/973 [==============================] - 0s - loss: 19.1692     \n",
      "Epoch 2/50\n",
      "973/973 [==============================] - 0s - loss: 8.3340     \n",
      "Epoch 3/50\n",
      "973/973 [==============================] - 0s - loss: 5.3187     \n",
      "Epoch 4/50\n",
      "973/973 [==============================] - 0s - loss: 3.7233     \n",
      "Epoch 5/50\n",
      "973/973 [==============================] - 0s - loss: 2.7271     \n",
      "Epoch 6/50\n",
      "973/973 [==============================] - 0s - loss: 2.0497     \n",
      "Epoch 7/50\n",
      "973/973 [==============================] - 0s - loss: 1.5647     \n",
      "Epoch 8/50\n",
      "973/973 [==============================] - 0s - loss: 1.2054     \n",
      "Epoch 9/50\n",
      "973/973 [==============================] - 0s - loss: 0.9332     \n",
      "Epoch 10/50\n",
      "973/973 [==============================] - 0s - loss: 0.7236     \n",
      "Epoch 11/50\n",
      "973/973 [==============================] - 0s - loss: 0.5606     \n",
      "Epoch 12/50\n",
      "973/973 [==============================] - 0s - loss: 0.4330     \n",
      "Epoch 13/50\n",
      "973/973 [==============================] - 0s - loss: 0.3328     \n",
      "Epoch 14/50\n",
      "973/973 [==============================] - 0s - loss: 0.2541     \n",
      "Epoch 15/50\n",
      "973/973 [==============================] - 0s - loss: 0.1924     \n",
      "Epoch 16/50\n",
      "973/973 [==============================] - 0s - loss: 0.1444     \n",
      "Epoch 17/50\n",
      "973/973 [==============================] - 0s - loss: 0.1072     \n",
      "Epoch 18/50\n",
      "973/973 [==============================] - 0s - loss: 0.0788     \n",
      "Epoch 19/50\n",
      "973/973 [==============================] - 0s - loss: 0.0573     \n",
      "Epoch 20/50\n",
      "973/973 [==============================] - 0s - loss: 0.0412     \n",
      "Epoch 21/50\n",
      "973/973 [==============================] - 0s - loss: 0.0295     \n",
      "Epoch 22/50\n",
      "973/973 [==============================] - 0s - loss: 0.0210     \n",
      "Epoch 23/50\n",
      "973/973 [==============================] - 0s - loss: 0.0152     \n",
      "Epoch 24/50\n",
      "973/973 [==============================] - 0s - loss: 0.0112     \n",
      "Epoch 25/50\n",
      "973/973 [==============================] - 0s - loss: 0.0086     \n",
      "Epoch 26/50\n",
      "973/973 [==============================] - 0s - loss: 0.0069     \n",
      "Epoch 27/50\n",
      "973/973 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 28/50\n",
      "973/973 [==============================] - 0s - loss: 0.0054     \n",
      "Epoch 29/50\n",
      "973/973 [==============================] - 0s - loss: 0.0050     \n",
      "Epoch 30/50\n",
      "973/973 [==============================] - 0s - loss: 0.0049     \n",
      "Epoch 31/50\n",
      "973/973 [==============================] - 0s - loss: 0.0048     \n",
      "Epoch 32/50\n",
      "973/973 [==============================] - 0s - loss: 0.0048     \n",
      "Epoch 33/50\n",
      "973/973 [==============================] - 0s - loss: 0.0048     \n",
      "Epoch 34/50\n",
      "973/973 [==============================] - 0s - loss: 0.0048     \n",
      "Epoch 35/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 36/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 37/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 38/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 39/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 40/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 41/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 42/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 43/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 44/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 45/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 46/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 47/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 48/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 49/50\n",
      "973/973 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 50/50\n",
      "973/973 [==============================] - 0s - loss: 0.0046     \n",
      "455/487 [===========================>..] - ETA: 0sEpoch 1/50\n",
      "974/974 [==============================] - 0s - loss: 23.3542     \n",
      "Epoch 2/50\n",
      "974/974 [==============================] - 0s - loss: 12.8094     \n",
      "Epoch 3/50\n",
      "974/974 [==============================] - 0s - loss: 2.0212     \n",
      "Epoch 4/50\n",
      "974/974 [==============================] - 0s - loss: 0.4324     \n",
      "Epoch 5/50\n",
      "974/974 [==============================] - 0s - loss: 0.1486     \n",
      "Epoch 6/50\n",
      "974/974 [==============================] - 0s - loss: 0.0562     \n",
      "Epoch 7/50\n",
      "974/974 [==============================] - 0s - loss: 0.0231     \n",
      "Epoch 8/50\n",
      "974/974 [==============================] - 0s - loss: 0.0114     \n",
      "Epoch 9/50\n",
      "974/974 [==============================] - 0s - loss: 0.0075     \n",
      "Epoch 10/50\n",
      "974/974 [==============================] - 0s - loss: 0.0063     \n",
      "Epoch 11/50\n",
      "974/974 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 12/50\n",
      "974/974 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 13/50\n",
      "974/974 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 14/50\n",
      "974/974 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 15/50\n",
      "974/974 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 16/50\n",
      "974/974 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 17/50\n",
      "974/974 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 18/50\n",
      "974/974 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 19/50\n",
      "974/974 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 20/50\n",
      "974/974 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 21/50\n",
      "974/974 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 22/50\n",
      "974/974 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 23/50\n",
      "974/974 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 24/50\n",
      "974/974 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 25/50\n",
      "974/974 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 26/50\n",
      "974/974 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 27/50\n",
      "974/974 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 28/50\n",
      "974/974 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 29/50\n",
      "974/974 [==============================] - 0s - loss: 0.0056     \n",
      "Epoch 30/50\n",
      "974/974 [==============================] - 0s - loss: 0.0056     \n",
      "Epoch 31/50\n",
      "974/974 [==============================] - 0s - loss: 0.0056     \n",
      "Epoch 32/50\n",
      "974/974 [==============================] - 0s - loss: 0.0055     \n",
      "Epoch 33/50\n",
      "974/974 [==============================] - 0s - loss: 0.0055     \n",
      "Epoch 34/50\n",
      "974/974 [==============================] - 0s - loss: 0.0054     \n",
      "Epoch 35/50\n",
      "974/974 [==============================] - 0s - loss: 0.0054     \n",
      "Epoch 36/50\n",
      "974/974 [==============================] - 0s - loss: 0.0053     \n",
      "Epoch 37/50\n",
      "974/974 [==============================] - 0s - loss: 0.0053     \n",
      "Epoch 38/50\n",
      "974/974 [==============================] - 0s - loss: 0.0052     \n",
      "Epoch 39/50\n",
      "974/974 [==============================] - 0s - loss: 0.0052     \n",
      "Epoch 40/50\n",
      "974/974 [==============================] - 0s - loss: 0.0051     \n",
      "Epoch 41/50\n",
      "974/974 [==============================] - 0s - loss: 0.0051     \n",
      "Epoch 42/50\n",
      "974/974 [==============================] - 0s - loss: 0.0050     \n",
      "Epoch 43/50\n",
      "974/974 [==============================] - 0s - loss: 0.0050     \n",
      "Epoch 44/50\n",
      "974/974 [==============================] - 0s - loss: 0.0049     \n",
      "Epoch 45/50\n",
      "974/974 [==============================] - 0s - loss: 0.0048     \n",
      "Epoch 46/50\n",
      "974/974 [==============================] - 0s - loss: 0.0048     \n",
      "Epoch 47/50\n",
      "974/974 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 48/50\n",
      "974/974 [==============================] - 0s - loss: 0.0046     \n",
      "Epoch 49/50\n",
      "974/974 [==============================] - 0s - loss: 0.0046     \n",
      "Epoch 50/50\n",
      "974/974 [==============================] - 0s - loss: 0.0045     \n",
      "445/486 [==========================>...] - ETA: 0sResults: 0.00 (0.00) MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator, net_X, net_Y, cv=3, n_jobs=1, verbose=1)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Standardized Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, nb_epoch=150, batch_size=5, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n=len(net_X), n_folds=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, net_X, net_Y, cv=kfold,n_jobs=1)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure And Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1460/1460 [==============================] - 1s - loss: 140.6089     \n",
      "Epoch 2/100\n",
      "1460/1460 [==============================] - 0s - loss: 131.9832     \n",
      "Epoch 3/100\n",
      "1460/1460 [==============================] - 1s - loss: 125.1841     \n",
      "Epoch 4/100\n",
      "1460/1460 [==============================] - 1s - loss: 119.8040     \n",
      "Epoch 5/100\n",
      "1460/1460 [==============================] - 0s - loss: 114.7322     \n",
      "Epoch 6/100\n",
      "1460/1460 [==============================] - 1s - loss: 108.6037     \n",
      "Epoch 7/100\n",
      "1460/1460 [==============================] - 0s - loss: 103.1065     \n",
      "Epoch 8/100\n",
      "1460/1460 [==============================] - 0s - loss: 99.1037     \n",
      "Epoch 9/100\n",
      "1460/1460 [==============================] - 0s - loss: 95.7965     \n",
      "Epoch 10/100\n",
      "1460/1460 [==============================] - 1s - loss: 92.9051     \n",
      "Epoch 11/100\n",
      "1460/1460 [==============================] - 0s - loss: 90.3096     \n",
      "Epoch 12/100\n",
      "1460/1460 [==============================] - 1s - loss: 87.9426     \n",
      "Epoch 13/100\n",
      "1460/1460 [==============================] - 0s - loss: 85.7599     \n",
      "Epoch 14/100\n",
      "1460/1460 [==============================] - 0s - loss: 83.7289     \n",
      "Epoch 15/100\n",
      "1460/1460 [==============================] - 1s - loss: 81.8286     \n",
      "Epoch 16/100\n",
      "1460/1460 [==============================] - 1s - loss: 80.0412     \n",
      "Epoch 17/100\n",
      "1460/1460 [==============================] - 0s - loss: 78.3507     \n",
      "Epoch 18/100\n",
      "1460/1460 [==============================] - 1s - loss: 76.7474     \n",
      "Epoch 19/100\n",
      "1460/1460 [==============================] - 0s - loss: 75.2221     \n",
      "Epoch 20/100\n",
      "1460/1460 [==============================] - 1s - loss: 73.7675     \n",
      "Epoch 21/100\n",
      "1460/1460 [==============================] - 1s - loss: 72.3759     \n",
      "Epoch 22/100\n",
      "1460/1460 [==============================] - 1s - loss: 71.0434     \n",
      "Epoch 23/100\n",
      "1460/1460 [==============================] - 0s - loss: 69.7655     \n",
      "Epoch 24/100\n",
      "1460/1460 [==============================] - 0s - loss: 68.5367     \n",
      "Epoch 25/100\n",
      "1460/1460 [==============================] - 1s - loss: 67.3544     \n",
      "Epoch 26/100\n",
      "1460/1460 [==============================] - 1s - loss: 66.2161     \n",
      "Epoch 27/100\n",
      "1460/1460 [==============================] - 0s - loss: 65.1180     \n",
      "Epoch 28/100\n",
      "1460/1460 [==============================] - 1s - loss: 64.0575     \n",
      "Epoch 29/100\n",
      "1460/1460 [==============================] - 1s - loss: 63.0340     \n",
      "Epoch 30/100\n",
      "1460/1460 [==============================] - 1s - loss: 62.0443     \n",
      "Epoch 31/100\n",
      "1460/1460 [==============================] - 0s - loss: 61.0873     \n",
      "Epoch 32/100\n",
      "1460/1460 [==============================] - 0s - loss: 60.1608     \n",
      "Epoch 33/100\n",
      "1460/1460 [==============================] - 0s - loss: 59.2628     \n",
      "Epoch 34/100\n",
      "1460/1460 [==============================] - 1s - loss: 58.3930     \n",
      "Epoch 35/100\n",
      "1460/1460 [==============================] - 0s - loss: 57.5498     \n",
      "Epoch 36/100\n",
      "1460/1460 [==============================] - 0s - loss: 56.7309     \n",
      "Epoch 37/100\n",
      "1460/1460 [==============================] - 1s - loss: 55.9365     \n",
      "Epoch 38/100\n",
      "1460/1460 [==============================] - 1s - loss: 55.1649     \n",
      "Epoch 39/100\n",
      "1460/1460 [==============================] - 1s - loss: 54.4154     \n",
      "Epoch 40/100\n",
      "1460/1460 [==============================] - 1s - loss: 53.6869     \n",
      "Epoch 41/100\n",
      "1460/1460 [==============================] - 1s - loss: 52.9780     \n",
      "Epoch 42/100\n",
      "1460/1460 [==============================] - 1s - loss: 52.2887     \n",
      "Epoch 43/100\n",
      "1460/1460 [==============================] - 1s - loss: 51.6177     \n",
      "Epoch 44/100\n",
      "1460/1460 [==============================] - 1s - loss: 50.9646     \n",
      "Epoch 45/100\n",
      "1460/1460 [==============================] - 1s - loss: 50.3278     \n",
      "Epoch 46/100\n",
      "1460/1460 [==============================] - 0s - loss: 49.7077     \n",
      "Epoch 47/100\n",
      "1460/1460 [==============================] - 0s - loss: 49.1028     \n",
      "Epoch 48/100\n",
      "1460/1460 [==============================] - 1s - loss: 48.5133     \n",
      "Epoch 49/100\n",
      "1460/1460 [==============================] - 1s - loss: 47.9382     \n",
      "Epoch 50/100\n",
      "1460/1460 [==============================] - 1s - loss: 47.3768     \n",
      "Epoch 51/100\n",
      "1460/1460 [==============================] - 0s - loss: 46.8292     \n",
      "Epoch 52/100\n",
      "1460/1460 [==============================] - 0s - loss: 46.2937     \n",
      "Epoch 53/100\n",
      "1460/1460 [==============================] - 1s - loss: 45.7709     \n",
      "Epoch 54/100\n",
      "1460/1460 [==============================] - 1s - loss: 45.2599     \n",
      "Epoch 55/100\n",
      "1460/1460 [==============================] - 1s - loss: 44.7604     \n",
      "Epoch 56/100\n",
      "1460/1460 [==============================] - 1s - loss: 44.2724     \n",
      "Epoch 57/100\n",
      "1460/1460 [==============================] - 1s - loss: 43.7943     \n",
      "Epoch 58/100\n",
      "1460/1460 [==============================] - 1s - loss: 43.3269     \n",
      "Epoch 59/100\n",
      "1460/1460 [==============================] - 1s - loss: 42.8694     \n",
      "Epoch 60/100\n",
      "1460/1460 [==============================] - 1s - loss: 42.4216     \n",
      "Epoch 61/100\n",
      "1460/1460 [==============================] - 0s - loss: 41.9828     \n",
      "Epoch 62/100\n",
      "1460/1460 [==============================] - 1s - loss: 41.5533     \n",
      "Epoch 63/100\n",
      "1460/1460 [==============================] - 0s - loss: 41.1323     \n",
      "Epoch 64/100\n",
      "1460/1460 [==============================] - 0s - loss: 40.7199     \n",
      "Epoch 65/100\n",
      "1460/1460 [==============================] - 0s - loss: 40.3154     \n",
      "Epoch 66/100\n",
      "1460/1460 [==============================] - 0s - loss: 39.9188     \n",
      "Epoch 67/100\n",
      "1460/1460 [==============================] - 1s - loss: 39.5299     \n",
      "Epoch 68/100\n",
      "1460/1460 [==============================] - 0s - loss: 39.1485     \n",
      "Epoch 69/100\n",
      "1460/1460 [==============================] - 0s - loss: 38.7740     \n",
      "Epoch 70/100\n",
      "1460/1460 [==============================] - 0s - loss: 38.4067     \n",
      "Epoch 71/100\n",
      "1460/1460 [==============================] - 1s - loss: 38.0458     \n",
      "Epoch 72/100\n",
      "1460/1460 [==============================] - 1s - loss: 37.6916     \n",
      "Epoch 73/100\n",
      "1460/1460 [==============================] - 1s - loss: 37.3439     \n",
      "Epoch 74/100\n",
      "1460/1460 [==============================] - 1s - loss: 37.0022     \n",
      "Epoch 75/100\n",
      "1460/1460 [==============================] - 1s - loss: 36.6668     \n",
      "Epoch 76/100\n",
      "1460/1460 [==============================] - 0s - loss: 36.3367     \n",
      "Epoch 77/100\n",
      "1460/1460 [==============================] - 0s - loss: 36.0126     \n",
      "Epoch 78/100\n",
      "1460/1460 [==============================] - 1s - loss: 35.6937     \n",
      "Epoch 79/100\n",
      "1460/1460 [==============================] - 1s - loss: 35.3804     \n",
      "Epoch 80/100\n",
      "1460/1460 [==============================] - 1s - loss: 35.0724     \n",
      "Epoch 81/100\n",
      "1460/1460 [==============================] - 1s - loss: 34.7692     \n",
      "Epoch 82/100\n",
      "1460/1460 [==============================] - 1s - loss: 34.4711     \n",
      "Epoch 83/100\n",
      "1460/1460 [==============================] - 0s - loss: 34.1778     \n",
      "Epoch 84/100\n",
      "1460/1460 [==============================] - 0s - loss: 33.8890     \n",
      "Epoch 85/100\n",
      "1460/1460 [==============================] - 1s - loss: 33.6049     \n",
      "Epoch 86/100\n",
      "1460/1460 [==============================] - 1s - loss: 33.3252     \n",
      "Epoch 87/100\n",
      "1460/1460 [==============================] - 1s - loss: 33.0499     \n",
      "Epoch 88/100\n",
      "1460/1460 [==============================] - 1s - loss: 32.7789     \n",
      "Epoch 89/100\n",
      "1460/1460 [==============================] - 1s - loss: 32.5117     \n",
      "Epoch 90/100\n",
      "1460/1460 [==============================] - 1s - loss: 32.2486     \n",
      "Epoch 91/100\n",
      "1460/1460 [==============================] - 1s - loss: 31.9896     \n",
      "Epoch 92/100\n",
      "1460/1460 [==============================] - 1s - loss: 31.7343     \n",
      "Epoch 93/100\n",
      "1460/1460 [==============================] - 0s - loss: 31.4830     \n",
      "Epoch 94/100\n",
      "1460/1460 [==============================] - 0s - loss: 31.2349     \n",
      "Epoch 95/100\n",
      "1460/1460 [==============================] - 0s - loss: 30.9906     \n",
      "Epoch 96/100\n",
      "1460/1460 [==============================] - 0s - loss: 30.7495     \n",
      "Epoch 97/100\n",
      "1460/1460 [==============================] - 1s - loss: 30.5121     \n",
      "Epoch 98/100\n",
      "1460/1460 [==============================] - 1s - loss: 30.2780     \n",
      "Epoch 99/100\n",
      "1460/1460 [==============================] - 1s - loss: 30.0473     \n",
      "Epoch 100/100\n",
      "1460/1460 [==============================] - 1s - loss: 29.8194     \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-a3930d8cc72c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/alexandertam/anaconda/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_final_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit_transform(net_X,net_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445/1460 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.56294288373973"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(net_X,net_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1460 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "flat_X = model.predict(net_X).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.1107624687890949"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsle(flat_X,net_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_actual</th>\n",
       "      <th>y_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208500.0</td>\n",
       "      <td>253919776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181500.0</td>\n",
       "      <td>222679504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223500.0</td>\n",
       "      <td>262643744.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>196645584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000.0</td>\n",
       "      <td>345683584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>143000.0</td>\n",
       "      <td>185529344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>307000.0</td>\n",
       "      <td>355179680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>255665296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>129900.0</td>\n",
       "      <td>176668256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>118000.0</td>\n",
       "      <td>143800896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>129500.0</td>\n",
       "      <td>159097936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>345000.0</td>\n",
       "      <td>449417184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>144000.0</td>\n",
       "      <td>165362112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>279500.0</td>\n",
       "      <td>299696160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>157000.0</td>\n",
       "      <td>184521728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>132000.0</td>\n",
       "      <td>167214224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>149000.0</td>\n",
       "      <td>187738416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>128949896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>159000.0</td>\n",
       "      <td>187847360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>139000.0</td>\n",
       "      <td>164482688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>325300.0</td>\n",
       "      <td>395795616.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>139400.0</td>\n",
       "      <td>161738816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>230000.0</td>\n",
       "      <td>276477088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>129900.0</td>\n",
       "      <td>166821792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>154000.0</td>\n",
       "      <td>184394480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>256300.0</td>\n",
       "      <td>302013056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>134800.0</td>\n",
       "      <td>160309728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>306000.0</td>\n",
       "      <td>365292896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>207500.0</td>\n",
       "      <td>241671088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>68500.0</td>\n",
       "      <td>79910112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>192140.0</td>\n",
       "      <td>222720752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>143750.0</td>\n",
       "      <td>165864480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>64500.0</td>\n",
       "      <td>104371680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>186500.0</td>\n",
       "      <td>226690640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>200869008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>174000.0</td>\n",
       "      <td>220606096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>120500.0</td>\n",
       "      <td>140779680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>394617.0</td>\n",
       "      <td>456169536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>149700.0</td>\n",
       "      <td>186216096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>197000.0</td>\n",
       "      <td>225222240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>191000.0</td>\n",
       "      <td>254737472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>149300.0</td>\n",
       "      <td>172788800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>310000.0</td>\n",
       "      <td>413865120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>121000.0</td>\n",
       "      <td>140906224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>179600.0</td>\n",
       "      <td>229545232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>129000.0</td>\n",
       "      <td>159198064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>157900.0</td>\n",
       "      <td>187158272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>240000.0</td>\n",
       "      <td>298173056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>112000.0</td>\n",
       "      <td>128726600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>92000.0</td>\n",
       "      <td>117579808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>136000.0</td>\n",
       "      <td>162395232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>287090.0</td>\n",
       "      <td>326714720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>145000.0</td>\n",
       "      <td>170378816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>84500.0</td>\n",
       "      <td>145591472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>185000.0</td>\n",
       "      <td>233411360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>175000.0</td>\n",
       "      <td>211284384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>210000.0</td>\n",
       "      <td>244701744.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>266500.0</td>\n",
       "      <td>318636512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>142125.0</td>\n",
       "      <td>166173520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>147500.0</td>\n",
       "      <td>178612944.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_actual        y_hat\n",
       "0     208500.0  253919776.0\n",
       "1     181500.0  222679504.0\n",
       "2     223500.0  262643744.0\n",
       "3     140000.0  196645584.0\n",
       "4     250000.0  345683584.0\n",
       "5     143000.0  185529344.0\n",
       "6     307000.0  355179680.0\n",
       "7     200000.0  255665296.0\n",
       "8     129900.0  176668256.0\n",
       "9     118000.0  143800896.0\n",
       "10    129500.0  159097936.0\n",
       "11    345000.0  449417184.0\n",
       "12    144000.0  165362112.0\n",
       "13    279500.0  299696160.0\n",
       "14    157000.0  184521728.0\n",
       "15    132000.0  167214224.0\n",
       "16    149000.0  187738416.0\n",
       "17     90000.0  128949896.0\n",
       "18    159000.0  187847360.0\n",
       "19    139000.0  164482688.0\n",
       "20    325300.0  395795616.0\n",
       "21    139400.0  161738816.0\n",
       "22    230000.0  276477088.0\n",
       "23    129900.0  166821792.0\n",
       "24    154000.0  184394480.0\n",
       "25    256300.0  302013056.0\n",
       "26    134800.0  160309728.0\n",
       "27    306000.0  365292896.0\n",
       "28    207500.0  241671088.0\n",
       "29     68500.0   79910112.0\n",
       "...        ...          ...\n",
       "1430  192140.0  222720752.0\n",
       "1431  143750.0  165864480.0\n",
       "1432   64500.0  104371680.0\n",
       "1433  186500.0  226690640.0\n",
       "1434  160000.0  200869008.0\n",
       "1435  174000.0  220606096.0\n",
       "1436  120500.0  140779680.0\n",
       "1437  394617.0  456169536.0\n",
       "1438  149700.0  186216096.0\n",
       "1439  197000.0  225222240.0\n",
       "1440  191000.0  254737472.0\n",
       "1441  149300.0  172788800.0\n",
       "1442  310000.0  413865120.0\n",
       "1443  121000.0  140906224.0\n",
       "1444  179600.0  229545232.0\n",
       "1445  129000.0  159198064.0\n",
       "1446  157900.0  187158272.0\n",
       "1447  240000.0  298173056.0\n",
       "1448  112000.0  128726600.0\n",
       "1449   92000.0  117579808.0\n",
       "1450  136000.0  162395232.0\n",
       "1451  287090.0  326714720.0\n",
       "1452  145000.0  170378816.0\n",
       "1453   84500.0  145591472.0\n",
       "1454  185000.0  233411360.0\n",
       "1455  175000.0  211284384.0\n",
       "1456  210000.0  244701744.0\n",
       "1457  266500.0  318636512.0\n",
       "1458  142125.0  166173520.0\n",
       "1459  147500.0  178612944.0\n",
       "\n",
       "[1460 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"y_hat\":flat_X,\"y_actual\":net_Y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445/1459 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1459,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnpredictions = model.predict(neural_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "makeSubmission(nnpredictions,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
